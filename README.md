# ğŸ AI Bug Report Categorizer  
### NLP-based Automated Bug Triage System

---

## ğŸ“Œ Problem Statement
Modern software teams receive hundreds of bug reports daily. Manually triaging these reports into categories such as UI, Performance, Security, or Crash is time-consuming and error-prone.

This project builds an **NLP-based machine learning system** that automatically classifies bug reports based on their textual descriptions, helping engineering teams **route issues faster and more accurately**.

---

## ğŸ¯ Objectives
- Automatically categorize bug reports using Natural Language Processing  
- Reduce manual effort in bug triaging  
- Provide explainable predictions for better trust and debugging  
- Simulate real-world DevOps workflows used in large engineering organizations  

---

## ğŸ› ï¸ Tech Stack
- **Programming Language:** Python  
- **Data Processing:** Pandas, NumPy  
- **Natural Language Processing:** NLTK, TF-IDF  
- **Machine Learning:** Scikit-learn (Logistic Regression)  
- **Environment:** Jupyter Notebook  

---

## ğŸ“‚ Project Structure
bug-report-categorizer/
â”œâ”€â”€ data/
â”‚ â””â”€â”€ bug_reports.csv
â”œâ”€â”€ notebook/
â”‚ â””â”€â”€ bug_report_classification.ipynb
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt

---

## ğŸ“Š Dataset Description
The dataset consists of bug reports with the following fields:

| Column Name | Description |
|------------|------------|
| `bug_id` | Unique identifier for each bug |
| `description` | Textual description of the bug |
| `category` | Bug type (UI, Performance, Security, Crash, Functional) |

The dataset is **synthetic but realistic**, designed to simulate real software issue descriptions commonly found in production systems.

---

## ğŸ” Approach

### 1. Text Preprocessing
- Lowercasing text
- Removing punctuation
- Stopword removal using NLTK

### 2. Feature Extraction
- Converted text into numerical vectors using **TF-IDF**
- Captures importance of technical keywords across bug descriptions

### 3. Model Training
- Used **Logistic Regression** for multiclass classification
- Chosen for its interpretability and strong baseline performance in NLP tasks

### 4. Model Evaluation
- Evaluated using Accuracy, Precision, Recall, and F1-Score
- Analyzed confusion matrix to identify misclassification patterns

---

## ğŸ“ˆ Results
- Successfully classifies bug reports into functional categories  
- Correctly identifies critical categories such as **Crash** and **Security**  
- Demonstrates a strong baseline for automated bug triaging  

---

## ğŸ§  Explainability
Model predictions are interpretable by inspecting **TF-IDF feature weights**, allowing visibility into which keywords influenced each classification decision.

This improves:
- Trust in model predictions  
- Debugging of misclassified issues  
- Transparency in ML-assisted tooling  

---

## âš–ï¸ Limitations
- Dataset size is limited and synthetic  
- Overlapping bug descriptions can cause ambiguity  
- Performance depends on the quality of textual descriptions  

---

## ğŸš€ Future Improvements
- Train on real-world GitHub or Azure DevOps issue datasets  
- Use sentence embeddings (e.g., BERT) for semantic understanding  
- Assign confidence scores to predictions  
- Integrate into DevOps pipelines for automated issue routing  

---

## ğŸ’¡ Use Cases
- Automated bug triaging in DevOps workflows  
- Productivity tools for large engineering teams  
- Scalable issue management systems  

---

## â­ Why This Project Matters
This project demonstrates:
- Practical NLP and machine learning skills  
- Real-world engineering problem solving  
- Explainable and responsible AI thinking  
- Strong alignment with large-scale software development workflows  
